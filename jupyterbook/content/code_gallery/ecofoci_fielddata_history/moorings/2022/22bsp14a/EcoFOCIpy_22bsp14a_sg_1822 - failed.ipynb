{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "educational-chosen",
   "metadata": {},
   "source": [
    "# Using EcoFOCIpy to process raw field data\n",
    "\n",
    "## Mooring / Timeseries Data\n",
    "\n",
    "Basic workflow for each instrument grouping is *(initial archive level)*:\n",
    "- Parse data from raw files into pandas dataframe\n",
    "- output initial files (pandas->csv) **ERDDAP NRT** when no meta data is added\n",
    "\n",
    "Convert to xarray dataframe for all following work *(working or final data level):\n",
    "- TODO: Add metadata from instrument yaml files and/or header info\n",
    "- ingest metadata from deployment/recovery records or cast logs\n",
    "- process data beyond simple file translate\n",
    "- apply any calibrations or corrections\n",
    "    + field corrections\n",
    "    + offsets\n",
    "    + instrument compensations\n",
    "    + some QC were available... this would be old-school simple bounds mostly\n",
    "- adjust time bounds and sample frequency (xarray dataframe)\n",
    "- save as CF netcdf via xarray: so many of the steps above are optional\n",
    "    + **ERDDAP NRT** if no corrections, offsets or time bounds are applied but some meta data is\n",
    "    + **Working and awaiting QC** has no ERDDAP representation and is a holding spot\n",
    "    + **ERDDAP Final** fully calibrated, qc'd and populated with meta information\n",
    "\n",
    "Plot for preview and QC\n",
    "- preview images (indiv and/or collectively)\n",
    "- manual qc process\n",
    "- automated qc process ML/AI\n",
    "\n",
    "Further refinenments for ERDDAP hosting:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "allied-miniature",
   "metadata": {},
   "source": [
    "## Example below is for RCM-SG (SeaGuard) it is different than the RCM-4/5/7/9/11 Processing pipeline which was developed by D.Pashinski.\n",
    "\n",
    "Future processing of this instrument can be a simplified (no markdown) process which can be archived so that the procedure can be traced or updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "studied-pollution",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import EcoFOCIpy.io.rcm_parser as rcm_parser #<- instrument specific\n",
    "import EcoFOCIpy.io.ncCFsave as ncCFsave\n",
    "import EcoFOCIpy.metaconfig.load_config as load_config\n",
    "import EcoFOCIpy.math.geotools as geotools\n",
    "import EcoFOCIpy.plots.TimeSeriesStickPlot as TSSP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "public-millennium",
   "metadata": {},
   "source": [
    "The sample_data_dir should be included in the github package but may not be included in the pip install of the package\n",
    "\n",
    "## Simple Processing - first step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "offensive-level",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_data_dir = '/Users/bell/Programs/EcoFOCIpy/'\n",
    "user_data_dir = '/Users/bell/ecoraid/2022/Moorings/22bsp14a/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "third-yellow",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/bell/ecoraid/2022/Moorings/22bsp14a/rawconverted/rcmsg/.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 12\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m###############################################################\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#init and load data\u001b[39;00m\n\u001b[1;32m     11\u001b[0m rcmsg_wop \u001b[38;5;241m=\u001b[39m rcm_parser\u001b[38;5;241m.\u001b[39mrcm_sg()\n\u001b[0;32m---> 12\u001b[0m (rcmsg_wop_data,rcmsg_wop_header) \u001b[38;5;241m=\u001b[39m \u001b[43mrcmsg_wop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatafile\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdatetime_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/src/ecofocipy/src/EcoFOCIpy/io/rcm_parser.py:206\u001b[0m, in \u001b[0;36mrcm_sg.parse\u001b[0;34m(filename, datetime_index)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m filename \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m , \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMust provide a datafile\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    204\u001b[0m header \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 206\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fobj:\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k, line \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(fobj\u001b[38;5;241m.\u001b[39mreadlines()):\n\u001b[1;32m    208\u001b[0m         header \u001b[38;5;241m=\u001b[39m header \u001b[38;5;241m+\u001b[39m [line]\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/bell/ecoraid/2022/Moorings/22bsp14a/rawconverted/rcmsg/.txt'"
     ]
    }
   ],
   "source": [
    "###############################################################\n",
    "# edit to point to {instrument sepcific} raw datafile \n",
    "datafile = user_data_dir+'rawconverted/rcmsg/.txt'\n",
    "instrument = 'RCMSG 1822'\n",
    "mooring_meta_file = user_data_dir+'logs/22BSP-14A.yaml'\n",
    "inst_meta_file = sample_data_dir+'staticdata/instr_metaconfig/rcmsg_cf.yaml'\n",
    "inst_shortname = 'rcmsg'\n",
    "###############################################################\n",
    "\n",
    "#init and load data\n",
    "rcmsg_wop = rcm_parser.rcm_sg()\n",
    "(rcmsg_wop_data,rcmsg_wop_header) = rcmsg_wop.parse(filename=datafile,datetime_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fe29ba-0cef-4162-851b-581c44f5aadd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rcmsg_wop_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073fa737",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rcmsg_wop_data.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae2e2e0-8842-40ff-b025-d8d6de9ca793",
   "metadata": {},
   "source": [
    "## Oxygen and other ancillary sensor adjusments\n",
    "\n",
    "Oxygen units should be adjusted and salinity corrections as we initiallize oxygen sensors as if in a 0 PSU environment.  Without a cond cell on board, this needs a secondary instrument.  See QC section below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ready-audit",
   "metadata": {},
   "source": [
    "## Time properties\n",
    "\n",
    "Its unusual that our clocks drift to the point of concern for our instruments (if an instrument is off by 3 minutes but only sampling hourly... regridding that data will result in minimal changes).  However, there are a few time oriented modifications that may need to be made.\n",
    "\n",
    "The can be classified into two categories:\n",
    "+ interpolate: these change the parameter values in accordance with the time edits\n",
    "    - linear interpolation is most common\n",
    "    - averaging of data and rebinning/resampling is also common (this needs to have the \"time lable\" thought out...)\n",
    "    - decimating is less common but does not impact the max/min values\n",
    "+ shift: these do not alter the measurements, just the timestamps they are associated with\n",
    "    - the round function will work well to correct small time errors/drifts **common**\n",
    "    - dropping extra precision on time (if you want hourly measurements, just remove all minute/second info... could cause large errors if rounding would have been more appropriate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supposed-bankruptcy",
   "metadata": {},
   "source": [
    "It is very easy to use pandas interplation and resample methods on the dataframe as is.  A few steps are suggested below:\n",
    "- parse out on-deck (predeployment and recovery) data.  This can be done via pandas or xarray but requires the mooring metadata to have been read in.  See future steps below.\n",
    "- even if the sample frequency is set to the desired measurement frequency, it would be good to perform a quick regridding as an assurance task\n",
    "- FOCI data is usualy 1min, 10min, 1hr - and the 1min data is a fairly new (sbe56) data stream\n",
    "    + subsampling high frequency data to lower frequency is easy via df.resample().mean() but it will label the new datapoint per default instructions.  The default is to label it with the left boundary of the bin.\n",
    "    + you may want to take the median instead of the mean for noisy data (fluorometer) , occasionally decimating may be more appropriate if you want to downsize the dataset size but not smear features\n",
    "    + shifting times can be a bit more involved.  There are two primary ways to do it, interpolate or shift (round)\n",
    "        - to interpolate, you will need to upsample your data to a higher frequency which will generate missing values, then interpolate (with a maximum gap size), then decimate.  This always has the artifact of smoothing data and decreasing the min/max values. **common on microcats and other 10min datasets**\n",
    "        - shifting usually just involves droping extra time \"digits\", if you want hourly, you could just drop the trailing minutes assuming you are just off the hour (8:05 -> 8:00) or you can round to the nearest time unit but niether of these changes the data value, just the time associated with it. **common on seacats and other hourly datasets**\n",
    "        - you may also be able to *shift* using the pandas datetime round function and specifing the desired frequency.\n",
    "    + I suggest if no change is needed... df.index.round(freq=*'your native sample freq'*)\n",
    "    \n",
    "    \n",
    "***Half Hour Sample - rounded/truncated***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297eb86c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rcmsg_wop_data.index = rcmsg_wop_data.index.round(freq='30T')\n",
    "rcmsg_wop_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "undefined-membrane",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rcmsg_wop_data.plot(figsize=(16,2),legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da7972e-c974-490a-a047-fcaa9337fc5e",
   "metadata": {},
   "source": [
    "## Visual QC of ancillary parameters\n",
    "\n",
    "We wont keep all the ancillary parameters as they are usually just used for QC of the currents (and are done in the aanderaa software)... we can put them in the preliminary csv file though... anyways, some quick visuals are below to inspire further investigation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f236ea-7d41-4c6a-a743-5c3e2f864bcd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt_sub = rcmsg_wop_data[['Battery Voltage(V)','Abs Tilt(Deg)','Ping Count','Strength(dB)','Heading(Deg.M)']]\n",
    "\n",
    "fig, ax = plt.subplots(nrows=len(plt_sub.columns), sharex=True, figsize=(16,8))\n",
    "\n",
    "for count,parameter in enumerate(plt_sub.columns):\n",
    "    plt_sub[parameter].plot(ax=ax[count],label=parameter)\n",
    "    ax[count].legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acknowledged-active",
   "metadata": {},
   "source": [
    "## Add Deployment meta information\n",
    "\n",
    "Two methods are available (if comming from python2 world - ordereddict was important... in py38 a dictionary is inherently ordered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "freelance-fairy",
   "metadata": {},
   "outputs": [],
   "source": [
    "#just a dictionary of dictionaries - simple\n",
    "with open(mooring_meta_file) as file:\n",
    "    mooring_config = yaml.full_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec76213b-10d4-4074-b45a-080ee0514dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#some parsing/cleaning for functions\n",
    "latlon_dec = geotools.latlon_convert(mooring_config['Deployment']['DeploymentLatitude'],\n",
    "                        mooring_config['Deployment']['DeploymentLongitude'])\n",
    "dep_date = mooring_config['Deployment']['DeploymentDateTimeGMT'].date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "israeli-begin",
   "metadata": {},
   "outputs": [],
   "source": [
    "mooring_config['Instrumentation'][instrument]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mysterious-cornwall",
   "metadata": {},
   "source": [
    "## Add Instrument meta information\n",
    "\n",
    "Time, depth, lat, lon should be added regardless (always our coordinates) but for a mooring site its going to be a (1,1,1,t) dataset\n",
    "The variables of interest should be read from the data file and matched to a key for naming.  That key is in the inst_config file seen below and should represent common conversion names in the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "checked-raise",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(inst_meta_file) as file:\n",
    "    inst_config = yaml.full_load(file)\n",
    "inst_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3402a326",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rcmsg data uses header info to name variables... but we want standard names from the dictionary I've created, so we need to rename column variables appropriately\n",
    "#rename values to appropriate names, if a value isn't in the .yaml file, you can add it\n",
    "\n",
    "#TODO: Manage ancillary instrumentation\n",
    "rcmsg_wop_data = rcmsg_wop_data.rename(columns={'Temperature(DegC)':'temperature',\n",
    "                        'O2Concentration(uM)':'oxy_concM',\n",
    "                        'AirSaturation(%)':'oxy_percentsat',\n",
    "                        'East(cm/s)':'u_curr_comp',\n",
    "                        'North(cm/s)':'v_curr_comp',\n",
    "                        'Abs Speed(cm/s)':'current_speed',\n",
    "                        'Temperature(Deg.C)':'oxy_temperature', #notice the '.' in the units... this seems to identify the oxy temp\n",
    "                        })\n",
    "\n",
    "### add a column for oxy_conc\n",
    "# rcmsg_wop_data.insert(0,'oxy_conc',np.nan)\n",
    "\n",
    "rcmsg_wop_data.sample()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64aeb762-c171-4eb1-a580-be7b000f15f1",
   "metadata": {},
   "source": [
    "## Magnetic Declination Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef83387d-a03d-4420-bba5-3bf03c2c93a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcmsg_wop.load(rcmsg_wop_data)\n",
    "\n",
    "dec_corr = rcmsg_wop.mag_dec_corr(latlon_dec[0],latlon_dec[1],dep_date,apply_correction=True)\n",
    "# dec_corr\n",
    "#set a declination correction note somewhere in attributes (currently in history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95da34b1-211e-4c5f-94c8-a3c30e849243",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Visualization of Mag Dec Corrected Current, Temperture and Oxy (if available) or any other parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4daff434-f517-4a69-a21f-89c987298ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "stickplot = TSSP.Timeseries1dStickPlot()\n",
    "fig,ax = stickplot.plot(rcmsg_wop_data.index,udata=rcmsg_wop_data['u_curr_comp'],vdata=rcmsg_wop_data['v_curr_comp'], rotate=0)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=len(plt_sub.columns), sharex=True, figsize=(16,8))\n",
    "plt_sub = rcmsg_wop_data[['temperature','oxy_temperature','oxy_concM','oxy_percentsat']]\n",
    "for count,parameter in enumerate(plt_sub.columns):\n",
    "    plt_sub[parameter].plot(ax=ax[count],label=parameter)\n",
    "    ax[count].legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varied-popularity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add meta data and prelim processing based on meta data\n",
    "# Convert to xarray and add meta information - save as CF netcdf file\n",
    "# pass -> data, instmeta, depmeta\n",
    "rcmsg_wop_nc = ncCFsave.EcoFOCI_CFnc(df=rcmsg_wop_data, \n",
    "                                instrument_yaml=inst_config, \n",
    "                                operation_yaml=mooring_config,\n",
    "                                operation_type='mooring', \n",
    "                                instrument_id=instrument, \n",
    "                                inst_shortname=inst_shortname)\n",
    "rcmsg_wop_nc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "asian-chambers",
   "metadata": {},
   "source": [
    "At this point, you could save your file with the `.xarray2netcdf_save()` method and have a functioning dataset.... but it would be very simple with no additional qc, meta-data, or tuned parameters for optimizing software like ferret or erddap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "practical-pennsylvania",
   "metadata": {},
   "outputs": [],
   "source": [
    "# expand the dimensions and coordinate variables\n",
    "# renames them appropriatley and prepares them for meta-filled values\n",
    "rcmsg_wop_nc.expand_dimensions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floral-operations",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build list from columsn in data - if a variable isn't in the yaml file, it will be dropped from the final data fields\n",
    "rcmsg_wop_nc.variable_meta_data(variable_keys=list(rcmsg_wop_data.columns.values),drop_missing=True)\n",
    "rcmsg_wop_nc.temporal_geospatioal_meta_data(depth='designed')\n",
    "#adding dimension meta needs to come after updating the dimension values... BUG?\n",
    "rcmsg_wop_nc.dimension_meta_data(variable_keys=['depth','latitude','longitude'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seventh-product",
   "metadata": {},
   "source": [
    "The following steps can happen in just about any order and are all meta-data driven.  Therefore, they are not required to have a functioning dataset, but they are required to have a well described dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "auburn-diversity",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add global attributes\n",
    "rcmsg_wop_nc.deployment_meta_add()\n",
    "rcmsg_wop_nc.get_xdf()\n",
    "\n",
    "#add instituitonal global attributes\n",
    "rcmsg_wop_nc.institution_meta_add()\n",
    "\n",
    "#add creation date/time - provenance data\n",
    "rcmsg_wop_nc.provinance_meta_add()\n",
    "\n",
    "#provide intial qc status field\n",
    "rcmsg_wop_nc.qc_status(qc_status='unknown')\n",
    "\n",
    "#declination correction as part of history\n",
    "rcmsg_wop_nc.history(f'Declination Correction = {dec_corr[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustained-hughes",
   "metadata": {},
   "source": [
    "## Save CF Netcdf files\n",
    "\n",
    "Currently stick to netcdf3 classic... but migrating to netcdf4 (default) may be no problems for most modern purposes.  Its easy enough to pass the `format` kwargs through to the netcdf api of xarray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modular-volunteer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine trim (not mandatory) and filename together (saves to test.nc without name)\n",
    "\n",
    "depth = str(int(mooring_config['Instrumentation'][instrument]['ActualDepth'])).zfill(4)\n",
    "# mooring_yaml['Instrumentation'][self.instrument_id]['DesignedDepth'])).zfill(4) #<-- alternative\n",
    "filename = \"\".join(mooring_config['MooringID'].split('-')).lower()+'_'+inst_shortname+'_'+depth+'m.nc'\n",
    "rcmsg_wop_nc.xarray2netcdf_save(xdf = rcmsg_wop_nc.autotrim_time(),\n",
    "                           filename=filename,format=\"NETCDF3_CLASSIC\")\n",
    "\n",
    "#csvoutput if necessary\n",
    "(rcmsg_wop_nc.get_xdf().to_dataframe()).to_csv(filename.replace('nc','csv'))\n",
    "(rcmsg_wop_nc.autotrim_time().to_dataframe()).to_csv(filename.replace('nc','.to_edit.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlike-breathing",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcmsg_wop_nc.get_xdf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "individual-nature",
   "metadata": {},
   "source": [
    "## Next Steps - These are usually deployment specific\n",
    "\n",
    "QC of data (plot parameters with other instruments)\n",
    "- be sure to updated the qc_status and the history\n",
    "\n",
    "### Open Netcdf File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f632da-dcb7-43de-aa65-db8fec054c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xa\n",
    "\n",
    "rcmsg_df = xa.load_dataset(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46518ef-074b-4bc8-a568-45c6c04951db",
   "metadata": {},
   "source": [
    "### Trimmed Velocity TimeSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d2aa65-1abf-47de-aea1-81e867f9cc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stickplot = TSSP.Timeseries1dStickPlot()\n",
    "fig,ax = stickplot.plot(rcmsg_df['time'],udata=rcmsg_df['u_curr_comp'][:,0,0,0],\n",
    "                        vdata=rcmsg_df['v_curr_comp'][:,0,0,0], rotate=0)\n",
    "\n",
    "fig.savefig(f\"images/{filename.replace('nc','_RCM_UV.png')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509a03ef-8894-408e-9135-8bbbfa0aeb68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt_sub = rcmsg_wop_data[['Battery Voltage(V)','Abs Tilt(Deg)','Ping Count','Strength(dB)','Heading(Deg.M)']]\n",
    "\n",
    "fig, ax = plt.subplots(nrows=len(plt_sub.columns), sharex=True, figsize=(16,8))\n",
    "\n",
    "for count,parameter in enumerate(plt_sub.columns):\n",
    "    plt_sub[parameter].plot(ax=ax[count],label=parameter)\n",
    "    ax[count].legend(loc='upper left')\n",
    "    \n",
    "fig.savefig(f\"images/{filename.replace('nc','_RCM_Scalars.png')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ffdf7f-bbe9-4f39-b77d-8963a35c0e16",
   "metadata": {},
   "source": [
    "### Compare against CTD's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6fc40e-8c3d-4343-a473-c3b3d83863b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import EcoFOCIpy.io.erddap as erddap\n",
    "\n",
    "url = \"http://ecofoci-field.pmel.noaa.gov:8082/erddap\"\n",
    "\n",
    "erddap.test_erddap_connection(url=url) #basic test for connection to internal server, no response is a good thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b19985c-41aa-46d3-98bf-5a9258841b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "depcast = erddap.erddapCTDretrieve(url=url,cruiseid='dy2306',qclevel='preliminary',concastno='073')\n",
    "reccast = erddap.erddapCTDretrieve(url=url,cruiseid='aq2301',qclevel='preliminary',concastno='006')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c339b5a-5f1f-4095-bd8b-fbb0acd6df52",
   "metadata": {},
   "outputs": [],
   "source": [
    "depcast.columns = [x.split(' ')[0] for x in depcast.columns]\n",
    "reccast.columns = [x.split(' ')[0] for x in reccast.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8648500-fddc-4c59-8845-a0148a97d949",
   "metadata": {},
   "source": [
    "some variable names switch between preliminary and final... this will eventually be resolved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705efb1f-a8be-4bb1-b8e6-f0785eec2f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot ctd values with a small circular radius and zoom in on near their equivalent mooring time span, we are looking for visual discrepencies\n",
    "#cycle through each depth and plot respective plot\n",
    "depth = int(mooring_config['Instrumentation'][instrument]['ActualDepth'])\n",
    "\n",
    "fig, ax = plt.subplots(2,figsize=(16, 4))\n",
    "rcmsg_df.temperature.plot(x=\"time\",hue=\"depth\",ax=ax[0], add_legend=False);\n",
    "rcmsg_df.oxy_temperature.plot(x=\"time\",hue=\"depth\",ax=ax[0], add_legend=False);\n",
    "ax[0].plot(pd.to_datetime(depcast[depcast['pressure'] == depth]['time']),\n",
    "        depcast[depcast['pressure'] == depth]['T_28'],\n",
    "        'o',markersize=20,markerfacecolor='none',markeredgecolor='red')\n",
    "ax[0].plot(pd.to_datetime(depcast[depcast['pressure'] == depth]['time']),\n",
    "        depcast[depcast['pressure'] == depth]['T_28'],\n",
    "        '+',markersize=10,markerfacecolor='none',markeredgecolor='red')\n",
    "ax[0].plot(pd.to_datetime(reccast[reccast['pressure'] == depth]['time']),\n",
    "        reccast[reccast['pressure'] == depth]['T_28'],\n",
    "        'o',markersize=20,markerfacecolor='none',markeredgecolor='red')\n",
    "ax[0].plot(pd.to_datetime(reccast[reccast['pressure'] == depth]['time']),\n",
    "        reccast[reccast['pressure'] == depth]['T_28'],\n",
    "        '+',markersize=10,markerfacecolor='none',markeredgecolor='red')\n",
    "\n",
    "rcmsg_df.oxy_percentsat.plot(x=\"time\",hue=\"depth\",ax=ax[1], add_legend=False);\n",
    "ax[1].plot(pd.to_datetime(depcast[depcast['pressure'] == depth]['time']),\n",
    "        depcast[depcast['pressure'] == depth]['OST_62'],\n",
    "        'o',markersize=20,markerfacecolor='none',markeredgecolor='red')\n",
    "ax[1].plot(pd.to_datetime(depcast[depcast['pressure'] == depth]['time']),\n",
    "        depcast[depcast['pressure'] == depth]['OST_62'],\n",
    "        '+',markersize=10,markerfacecolor='none',markeredgecolor='red')\n",
    "ax[1].plot(pd.to_datetime(reccast[reccast['pressure'] == depth]['time']),\n",
    "        reccast[reccast['pressure'] == depth]['OST_62'],\n",
    "        'o',markersize=20,markerfacecolor='none',markeredgecolor='red')\n",
    "ax[1].plot(pd.to_datetime(reccast[reccast['pressure'] == depth]['time']),\n",
    "        reccast[reccast['pressure'] == depth]['OST_62'],\n",
    "        '+',markersize=10,markerfacecolor='none',markeredgecolor='red')\n",
    "\n",
    "ax[1].set_ylim([25,125])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce72b6fb-726a-4f6f-822b-dbd961874fcd",
   "metadata": {},
   "source": [
    "### QC Notes from plots\n",
    "\n",
    "- ***need to correct oxygen with local salinity***\n",
    "- trim deploy/recovery better\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b18644-33cb-4d9c-a058-aa560bf7b47c",
   "metadata": {},
   "source": [
    "### Correct Oxygen to local Salinity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15c4165-a8b3-4a68-929a-c66512955fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get salinity from external source\n",
    "\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import datetime\n",
    "import EcoFOCIpy.io.erddap as erddap\n",
    "\n",
    "url = \"http://akutan.pmel.noaa.gov:8080/erddap\"\n",
    "\n",
    "erddap.test_erddap_connection(url=url) #basic test for connection to internal server, no response is a good thing\n",
    "\n",
    "sdf = erddap.erddapMooredInstretrieve(url=url,mooringid='23kum2a',qclevel='final',instrid='23kum2a_s37_0031m')\n",
    "sdf.set_index(pd.to_datetime(sdf['time (UTC)']),inplace=True)\n",
    "sdf = sdf.drop(columns='time (UTC)').tz_localize(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd1be52-e847-44d8-9af5-b725df13c857",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_30 = pd.merge(rcmsg_df.temperature[:,0,0,0].to_dataframe(),sdf['salinity (PSU)'],\n",
    "                  how='left',left_index=True,right_index=True).interpolate()\n",
    "sdf_30.index.name = 'time'\n",
    "sdf_30 = sdf_30.reset_index().set_index(['time','latitude','longitude','depth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad890db-b222-4d6b-b5fd-c93c06e91cdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from EcoFOCIpy.math import aandopt_oxy_corr as aand_oxy\n",
    "\n",
    "# if you just want to correct and move on - pass the trimmed data in e.g. : sbe16_wop_nc.autotrim_time().oxy_conc\n",
    "# if you want to evaluate deck info - pass the untrimmed data in e.g. : sbe16_wop_nc.get_xdf().oxy_conc\n",
    "\n",
    "#depth correction... usually small\n",
    "temp_oxycorr = aand_oxy.o2_dep_comp(oxygen_conc=rcmsg_df.oxy_concM,\n",
    "                     depth=int(mooring_config['Instrumentation'][instrument]['ActualDepth']))\n",
    "\n",
    "#sal correction... big! will need to come from a different isntrument or be a lucky guess\n",
    "temp_oxycorr = aand_oxy.o2_sal_comp(oxygen_conc=temp_oxycorr,\n",
    "                                    salinity=sdf_30.to_xarray()['salinity (PSU)'],\n",
    "                                    temperature=rcmsg_df.temperature)\n",
    "\n",
    "#units adjustment... not so big from uM to um/kg\n",
    "temp_oxycorr_umkg = aand_oxy.o2_molar2umkg(oxygen_conc=temp_oxycorr,\n",
    "                                    salinity=sdf_30.to_xarray()['salinity (PSU)'],\n",
    "                                       temperature=rcmsg_df.temperature,\n",
    "                                       pressure=int(mooring_config['Instrumentation'][instrument]['ActualDepth']))\n",
    "\n",
    "#saturation calculation\n",
    "temp_oxysat = aand_oxy.o2_percent_sat(oxygen_conc=temp_oxycorr,\n",
    "                                    salinity=sdf_30.to_xarray()['salinity (PSU)'],\n",
    "                                           temperature=rcmsg_df.temperature,\n",
    "                                           pressure=int(mooring_config['Instrumentation'][instrument]['ActualDepth']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d1b39f-59e0-4258-ab5d-43a57583f128",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcmsg_df['oxy_conc'] = rcmsg_df.oxy_concM * 0\n",
    "rcmsg_df['oxy_conc'] = temp_oxycorr_umkg\n",
    "rcmsg_df['oxy_conc'] = rcmsg_df.oxy_conc\n",
    " #<-- this needs to go to the netcdf file.\n",
    "rcmsg_df.attrs.update({'history':rcmsg_df.history + '\\nOxygen Salinity Corrected'})\n",
    "\n",
    "rcmsg_df.drop('oxy_concM').to_netcdf(filename,format='NETCDF3_CLASSIC',encoding={'time':{'units':'days since 1900-01-01'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2542fe-9c26-41e6-9374-63c133e338ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot ctd values with a small circular radius and zoom in on near their equivalent mooring time span, we are looking for visual discrepencies\n",
    "#cycle through each depth and plot respective plot\n",
    "# depth = int(mooring_config['Instrumentation'][instrument]['ActualDepth'])\n",
    "\n",
    "fig, ax = plt.subplots(1,figsize=(16, 2))\n",
    "rcmsg_df.oxy_conc.plot(x=\"time\",hue=\"depth\",ax=ax, add_legend=False);\n",
    "rcmsg_df.oxy_concM.plot(x=\"time\",hue=\"depth\",ax=ax, add_legend=False);\n",
    "ax.plot(pd.to_datetime(depcast[depcast['pressure'] == depth]['time']),\n",
    "        depcast[depcast['pressure'] == depth]['O_65'],\n",
    "        'o',markersize=20,markerfacecolor='none',markeredgecolor='red')\n",
    "ax.plot(pd.to_datetime(depcast[depcast['pressure'] == depth]['time']),\n",
    "        depcast[depcast['pressure'] == depth]['O_65'],\n",
    "        '+',markersize=10,markerfacecolor='none',markeredgecolor='red')\n",
    "ax.plot(pd.to_datetime(reccast[reccast['pressure'] == depth]['time']),\n",
    "        reccast[reccast['pressure'] == depth]['O_65'],\n",
    "        'o',markersize=20,markerfacecolor='none',markeredgecolor='red')\n",
    "ax.plot(pd.to_datetime(reccast[reccast['pressure'] == depth]['time']),\n",
    "        reccast[reccast['pressure'] == depth]['O_65'],\n",
    "        '+',markersize=10,markerfacecolor='none',markeredgecolor='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd33d6df-ca8e-4396-a0b8-f7fa2cfed55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot ctd values with a small circular radius and zoom in on near their equivalent mooring time span, we are looking for visual discrepencies\n",
    "#cycle through each depth and plot respective plot\n",
    "depth = int(mooring_config['Instrumentation'][instrument]['ActualDepth'])\n",
    "\n",
    "fig, ax = plt.subplots(1,figsize=(16, 2))\n",
    "rcmsg_df.oxy_percentsat.plot(x=\"time\",hue=\"depth\",ax=ax, add_legend=False);\n",
    "# rcmsg_df.oxy_concM.plot(x=\"time\",hue=\"depth\",ax=ax, add_legend=False);\n",
    "ax.plot(pd.to_datetime(depcast[depcast['pressure'] == depth]['time']),\n",
    "        depcast[depcast['pressure'] == depth]['OST_62'],\n",
    "        'o',markersize=20,markerfacecolor='none',markeredgecolor='red')\n",
    "ax.plot(pd.to_datetime(depcast[depcast['pressure'] == depth]['time']),\n",
    "        depcast[depcast['pressure'] == depth]['OST_62'],\n",
    "        '+',markersize=10,markerfacecolor='none',markeredgecolor='red')\n",
    "ax.plot(pd.to_datetime(reccast[reccast['pressure'] == depth]['time']),\n",
    "        reccast[reccast['pressure'] == depth]['OST_62'],\n",
    "        'o',markersize=20,markerfacecolor='none',markeredgecolor='red')\n",
    "ax.plot(pd.to_datetime(reccast[reccast['pressure'] == depth]['time']),\n",
    "        reccast[reccast['pressure'] == depth]['OST_62'],\n",
    "        '+',markersize=10,markerfacecolor='none',markeredgecolor='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8816887b-3948-4382-a409-4e4da9234524",
   "metadata": {},
   "source": [
    "### Post Manual QC load data and rebuild nc file\n",
    "\n",
    "- using excel for a few points or a dynamic web map for multiple (a tool on ecofoci-field.pmel.noaa.gov) or any other method to identify spikes\n",
    "**NOTE** if you use excel, be cautious about how your time is formatted (its important) - use custom formatting and make it of the form `yyyy-mm-ddTHH:MM:SSZ` to assure proper read in to xarray\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e8880e-4eff-4097-a9c0-f4d709dab9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import datetime\n",
    "\n",
    "# rcmsg_df_qc = pd.read_csv(user_data_dir+'working/'+filename.replace('nc','to_edit.csv'), index_col=['time','latitude','longitude','depth']) #order is important\n",
    "rcmsg_df_qc = pd.read_csv(filename.replace('nc','to_edit.csv'), \n",
    "                          index_col=['time','latitude','longitude','depth']) #order is important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b0e325-e689-4986-878b-bef6aa673b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcmsg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41c7ff5-fbf4-44e6-9c61-c63bef1a5844",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcmsg_df['oxy_percentsat'].values = xr.Dataset.from_dataframe(rcmsg_df_qc)['oxy_percentsat']\n",
    "rcmsg_df['oxy_concM'].values = xr.Dataset.from_dataframe(rcmsg_df_qc)['oxy_concM']\n",
    "# rcmsg_df['oxy_temperature'].values = xr.Dataset.from_dataframe(rcmsg_df_qc)['oxy_temperature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237609f6-135a-48c5-8d35-6791082943a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcmsg_df.attrs.update({'QC_indicator': 'ProbablyGood'})\n",
    "rcmsg_df.attrs.update({'history':(rcmsg_df.history + \"\\nQC'd: \"+ str(datetime.datetime.today()))})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09981df-a331-4bf2-9c59-ea62d31e5764",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcmsg_df.attrs.update({'date_modified':str(datetime.datetime.today())})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e7e217-b6a3-4508-a3a3-532c713f310d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcmsg_df.to_netcdf(filename,format='NETCDF3_CLASSIC',encoding={'time':{'units':'days since 1900-01-01'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08043e7c-732e-468d-a57c-64d349c560fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py310] *",
   "language": "python",
   "name": "conda-env-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
