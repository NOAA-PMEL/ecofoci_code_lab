{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "educational-chosen",
   "metadata": {},
   "source": [
    "# Using EcoFOCIpy to process raw field data\n",
    "\n",
    "## DY2209 (Spring Mooring Cruise - Oscar Dyson)\n",
    "\n",
    "## BO Oxygen Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "studied-pollution",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "import glob\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import EcoFOCIpy.io.sbe_ctd_parser as sbe_ctd_parser #<- instrument specific\n",
    "import EcoFOCIpy.io.ncCFsave as ncCFsave\n",
    "import EcoFOCIpy.metaconfig.load_config as load_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "offensive-level",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_data_dir = '/Users/bell/ecoraid/2022/CTDcasts/dy2209/' #root path to cruise directory\n",
    "ecofocipy_dir = '/Users/bell/Programs/EcoFOCIpy/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "third-yellow",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /Users/bell/ecoraid/2022/CTDcasts/dy2209/rawconverted/CTD001.btl\n",
      "Processing /Users/bell/ecoraid/2022/CTDcasts/dy2209/rawconverted/CTD002.btl\n",
      "Processing /Users/bell/ecoraid/2022/CTDcasts/dy2209/rawconverted/CTD003.btl\n",
      "Processing /Users/bell/ecoraid/2022/CTDcasts/dy2209/rawconverted/CTD004.btl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bell/src/ecofocipy/src/EcoFOCIpy/io/sbe_ctd_parser.py:90: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  ctd_df = pd.concat([ctd_df,row])\n",
      "/Users/bell/src/ecofocipy/src/EcoFOCIpy/io/sbe_ctd_parser.py:90: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  ctd_df = pd.concat([ctd_df,row])\n",
      "/Users/bell/src/ecofocipy/src/EcoFOCIpy/io/sbe_ctd_parser.py:90: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  ctd_df = pd.concat([ctd_df,row])\n",
      "/Users/bell/src/ecofocipy/src/EcoFOCIpy/io/sbe_ctd_parser.py:90: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  ctd_df = pd.concat([ctd_df,row])\n"
     ]
    }
   ],
   "source": [
    "###############################################################\n",
    "# edit to point to {cruise sepcific} raw datafiles \n",
    "datafile = sample_data_dir+'rawconverted/' #<- point to cruise and process all files within\n",
    "oxydatafile = sample_data_dir+'working/DiscreteOxygens/DY2209 Oxygen Data.txt' #<- point to cruise and process all files within\n",
    "cruise_name = 'dy2209' #no hyphens\n",
    "cruise_meta_file = sample_data_dir+'logs/DY2209.yaml'\n",
    "inst_meta_file = sample_data_dir+'logs/FOCI_standard_CTDpOxy.yaml' #<- copy to each deployment for simplicity?\n",
    "group_meta_file = ecofocipy_dir+'staticdata/institutional_meta_example.yaml'\n",
    "###############################################################\n",
    "\n",
    "#init and load data\n",
    "cruise = sbe_ctd_parser.sbe_btl()\n",
    "filename_list = sorted(glob.glob(datafile + '*.btl'))\n",
    "\n",
    "cruise_data = cruise.manual_parse(filename_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b60694-2698-480d-98ba-4ea070b2e4b0",
   "metadata": {},
   "source": [
    "## Load csv Oxygen File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0fb5c09-d76d-455c-89f4-3ba6a7954f00",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cast</th>\n",
       "      <th>Niskin</th>\n",
       "      <th>Oxygen (uM)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>296.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>296.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>297.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>302.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>303.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>292.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>356.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>304.86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cast  Niskin  Oxygen (uM)\n",
       "0     1       1       296.16\n",
       "1     1       1       296.96\n",
       "2     1       2       297.32\n",
       "3     1       3       302.70\n",
       "4     1       5       303.15\n",
       "5     2       5       292.24\n",
       "6     3       1       356.20\n",
       "7     4       6       304.86"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oxy_data = pd.read_csv(oxydatafile,delimiter='\\t')\n",
    "oxy_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b5ed69-2eac-4a61-a597-1beac3cf628b",
   "metadata": {},
   "source": [
    "## Merge Bottle and Nutrient Data but drop non nutrient vars?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "586c00a1-4b89-4488-927c-a9d84df24225",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "keep_param = ['bottle','prdm']\n",
    "\n",
    "for cast,cdata in cruise_data.items():\n",
    "    try:\n",
    "        matchcast = int((cast.split('.')[0]).lower().split('ctd')[-1])\n",
    "        cruise_data[cast] = pd.merge(oxy_data[oxy_data['Cast']==matchcast],cdata.reset_index()[keep_param],right_on='bottle',left_on='Niskin').set_index('bottle').drop(columns=['Cast'])\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acknowledged-active",
   "metadata": {},
   "source": [
    "## Add Deployment meta information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "freelance-fairy",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#just a dictionary of dictionaries - simple\n",
    "with open(cruise_meta_file) as file:\n",
    "    cruise_config = yaml.full_load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mysterious-cornwall",
   "metadata": {},
   "source": [
    "## Add Instrument meta information\n",
    "\n",
    "Time, depth, lat, lon should be added regardless (always our coordinates) but for a mooring site its going to be a (1,1,1,t) dataset\n",
    "The variables of interest should be read from the data file and matched to a key for naming.  That key is in the inst_config file seen below and should represent common conversion names in the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "checked-raise",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(inst_meta_file) as file:\n",
    "    inst_oxy_config = yaml.full_load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56119e2f",
   "metadata": {},
   "source": [
    "## Add institutional meta-information\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24b2c8b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(group_meta_file) as file:\n",
    "    group_config = yaml.full_load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustained-hughes",
   "metadata": {},
   "source": [
    "## Save CF Netcdf files\n",
    "\n",
    "Currently stick to netcdf3 classic... but migrating to netcdf4 (default) may be no problems for most modern purposes.  Its easy enough to pass the `format` kwargs through to the netcdf api of xarray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "modular-volunteer",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bell/src/ecofocipy/src/EcoFOCIpy/io/ncCFsave.py:320: UserWarning: Times can't be serialized faithfully to int64 with requested units 'days since 1900-01-01'. Resolution of 'minutes' needed. Serializing times to floating point instead. Set encoding['dtype'] to integer dtype to serialize to int64. Set encoding['dtype'] to floating point dtype to silence this warning.\n",
      "  xdf.to_netcdf(filename,format=kwargs['format'],encoding={'time':{'units':'days since 1900-01-01'}})\n",
      "/Users/bell/src/ecofocipy/src/EcoFOCIpy/io/ncCFsave.py:320: UserWarning: Times can't be serialized faithfully to int64 with requested units 'days since 1900-01-01'. Resolution of 'minutes' needed. Serializing times to floating point instead. Set encoding['dtype'] to integer dtype to serialize to int64. Set encoding['dtype'] to floating point dtype to silence this warning.\n",
      "  xdf.to_netcdf(filename,format=kwargs['format'],encoding={'time':{'units':'days since 1900-01-01'}})\n",
      "/Users/bell/src/ecofocipy/src/EcoFOCIpy/io/ncCFsave.py:320: UserWarning: Times can't be serialized faithfully to int64 with requested units 'days since 1900-01-01'. Resolution of 'hours' needed. Serializing times to floating point instead. Set encoding['dtype'] to integer dtype to serialize to int64. Set encoding['dtype'] to floating point dtype to silence this warning.\n",
      "  xdf.to_netcdf(filename,format=kwargs['format'],encoding={'time':{'units':'days since 1900-01-01'}})\n",
      "/Users/bell/src/ecofocipy/src/EcoFOCIpy/io/ncCFsave.py:320: UserWarning: Times can't be serialized faithfully to int64 with requested units 'days since 1900-01-01'. Resolution of 'minutes' needed. Serializing times to floating point instead. Set encoding['dtype'] to integer dtype to serialize to int64. Set encoding['dtype'] to floating point dtype to silence this warning.\n",
      "  xdf.to_netcdf(filename,format=kwargs['format'],encoding={'time':{'units':'days since 1900-01-01'}})\n"
     ]
    }
   ],
   "source": [
    "#loop over all casts and perform tasks shown above\n",
    "\n",
    "for cast in cruise_data.keys():\n",
    "    try:\n",
    "        cruise_data[cast] = cruise_data[cast].rename(columns={\n",
    "                            'O2 (uM)':'O2',\n",
    "                            'O2, uM/l':'O2',\n",
    "                            'Niskin':'BTLID',\n",
    "                            'prdm':'pressure',\n",
    "                            'empty':'empty', #this will be ignored\n",
    "                            'flag':'flag'})\n",
    "\n",
    "        cruise_data_nc = ncCFsave.EcoFOCI_CFnc(df=cruise_data[cast], \n",
    "                                    instrument_yaml=inst_oxy_config, \n",
    "                                    operation_yaml=cruise_config,\n",
    "                                    operation_type='ctd')\n",
    "\n",
    "        cruise_data_nc.expand_dimensions(dim_names=['latitude','longitude','time'],geophys_sort=False)\n",
    "\n",
    "        cruise_data_nc.variable_meta_data(variable_keys=list(cruise_data[cast].columns.values),drop_missing=False)\n",
    "        #adding dimension meta needs to come after updating the dimension values... BUG?\n",
    "        cruise_data_nc.dimension_meta_data(variable_keys=['time','latitude','longitude'])\n",
    "        cruise_data_nc.temporal_geospatioal_meta_data_ctd(positiveE=False,conscastno=cast.split('.')[0])\n",
    "\n",
    "        #add global attributes\n",
    "        cruise_data_nc.deployment_meta_add(conscastno=cast.split('.')[0].upper())\n",
    "\n",
    "        #add instituitonal global attributes\n",
    "        cruise_data_nc.institution_meta_add(group_config)\n",
    "\n",
    "        #add creation date/time - provenance data\n",
    "        cruise_data_nc.provinance_meta_add()\n",
    "\n",
    "        #provide intial qc status field\n",
    "        cruise_data_nc.qc_status(qc_status='excellent') #<- options are unknown, excellent, probably good, mixed, unqcd\n",
    "\n",
    "        cruise_data_nc.xarray2netcdf_save(xdf = cruise_data_nc.get_xdf(),\n",
    "                                   filename=cruise_name+'c'+cast.lower().split('d')[-1].split('.')[0].zfill(3)+'_oxy.nc',format=\"NETCDF3_CLASSIC\")\n",
    "    except KeyError:\n",
    "        print(f'Skipping {cast}')\n",
    "    except RuntimeError:\n",
    "        print(f'Skipping & Removing {cast}')\n",
    "        os.remove(path=cruise_name+'c'+cast.lower().split('d')[-1].split('.')[0].zfill(3)+'_oxy.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "individual-nature",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "QC of data (plot parameters with other instruments)\n",
    "- be sure to updated the qc_status and the history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py311]",
   "language": "python",
   "name": "conda-env-py311-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
