{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "educational-chosen",
   "metadata": {},
   "source": [
    "# Using EcoFOCIpy to process raw field data - skq202312\n",
    "\n",
    "*SKQ202312 - Ecofoci Fall Mooring Cruise*\n",
    "\n",
    "**Processed by Shaun Bell / UAF has final QC (Seth Danielson)**\n",
    "\n",
    "A duplicate column of Fluorescence shows up \n",
    "## CTD / Profile Data\n",
    "\n",
    "Basic workflow for each instrument grouping is *(initial archive level)*:\n",
    "- SBE workflow must happen first **done (performed on seperate windows system to convert to cnv)**\n",
    "- output initial files (pandas->csv) **ERDDAP NRT** when no meta data is added.  Good for quick analysis\n",
    "\n",
    "Other than hosting on an erddap server, the above can be done at sea\n",
    "\n",
    "For furthur processing, QC and archiving, the following tasks are to be done *(working or final data level)*:\n",
    "- Add metadata from cruise yaml files created from cast logs\n",
    "- apply any calibrations or corrections\n",
    "    + field corrections\n",
    "    + offsets\n",
    "    + spike analysis\n",
    "    + some QC were available... this would be old-school simple bounds mostly\n",
    "- save as CF netcdf via xarray or potentially csv file: so many of the steps above are optional\n",
    "    + **ERDDAP NRT** if no corrections, offsets or time bounds are applied but some meta data is (can be csv as this is useful at sea)\n",
    "    + **Working and awaiting QC** has no ERDDAP representation and is a holding spot\n",
    "    + **ERDDAP Final** fully calibrated, qc'd and populated with meta information\n",
    "\n",
    "Plot for preview and QC\n",
    "- TSSigma, TOXYChlor, TurbParTrans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "studied-pollution",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import glob\n",
    "\n",
    "import EcoFOCIpy.io.sbe_ctd_parser as sbe_ctd_parser #<- instrument specific\n",
    "import EcoFOCIpy.io.ncCFsave as ncCFsave\n",
    "import EcoFOCIpy.metaconfig.load_config as load_config\n",
    "import EcoFOCIpy.math.geotools as geotools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "allied-miniature",
   "metadata": {},
   "source": [
    "## At Sea NRT Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "offensive-level",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data_dir = '/Users/bell/ecoraid/2022/CTDcasts/skq202214s/' #root path to cruise directory\n",
    "ecofocipy_dir = '/Users/bell/Programs/EcoFOCIpy/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7705c0f1-a4cc-41c4-9d27-2a5809264638",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "###############################################################\n",
    "# edit to point to {cruise sepcific} raw datafiles \n",
    "datafile = sample_data_dir+'rawconverted/' #<- point to cruise and process all files within\n",
    "cruise_name = 'SKQ202214S' #no hyphens\n",
    "inst_meta_file = sample_data_dir+'logs/FOCI_standard_CTD.yaml'\n",
    "###############################################################\n",
    "\n",
    "#init and load data\n",
    "cruise = sbe_ctd_parser.sbe9_11p()\n",
    "filename_list = sorted(glob.glob(datafile + '*.cnv'))\n",
    "\n",
    "(cruise_data,cruise_header) = cruise.parse(filename_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52b036fa-4a09-4298-ae34-a59dff8e01ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#this line adds available NMEA data to csv files for NRT/Preliminary erddap hosting... if there isn't an NMEA string, you will have to pull the locations\n",
    "#  from the cast logs and output either a .nc or a more elaborate csv file furthur in to this process\n",
    "NMEA_location = True\n",
    "verbose = False\n",
    "\n",
    "if NMEA_location:\n",
    "    \n",
    "    for cast in cruise_header.keys():\n",
    "        cruise_data[cast][['time','latitude','longitude','profileid']] = ('0',0,0,'0')\n",
    "        cruise_data[cast][['time','latitude','longitude','profileid']] = (cruise_header[cast]['NMEAtime'],\n",
    "              geotools.latlon_convert(cruise_header[cast]['NMEALat'],cruise_header[cast]['NMEALon'])[0],\n",
    "              geotools.latlon_convert(cruise_header[cast]['NMEALat'],cruise_header[cast]['NMEALon'])[1],\n",
    "              cast.split('.')[0])\n",
    "        if verbose:\n",
    "            print(cruise_header[cast]['NMEAtime'],\n",
    "                  geotools.latlon_convert(cruise_header[cast]['NMEALat'],cruise_header[cast]['NMEALon'])[0],\n",
    "                  geotools.latlon_convert(cruise_header[cast]['NMEALat'],cruise_header[cast]['NMEALon'])[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84b99d86-fd86-49dd-8d5e-64badd56fb5e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Cast skq202214s_001avg.cnv\n",
      "Processing Cast skq202214s_002avg.cnv\n",
      "Processing Cast skq202214s_003avg.cnv\n",
      "Processing Cast skq202214s_004avg.cnv\n",
      "Processing Cast skq202214s_005avg.cnv\n",
      "Processing Cast skq202214s_006avg.cnv\n",
      "Processing Cast skq202214s_007avg.cnv\n",
      "Processing Cast skq202214s_008avg.cnv\n",
      "Processing Cast skq202214s_009avg.cnv\n",
      "Processing Cast skq202214s_010avg.cnv\n",
      "Processing Cast skq202214s_011avg.cnv\n",
      "Processing Cast skq202214s_012avg.cnv\n",
      "Processing Cast skq202214s_013avg.cnv\n",
      "Processing Cast skq202214s_014avg.cnv\n",
      "Processing Cast skq202214s_015avg.cnv\n",
      "Processing Cast skq202214s_016avg.cnv\n",
      "Processing Cast skq202214s_017avg.cnv\n",
      "Processing Cast skq202214s_018avg.cnv\n",
      "Processing Cast skq202214s_019avg.cnv\n",
      "Processing Cast skq202214s_020avg.cnv\n",
      "Processing Cast skq202214s_021avg.cnv\n",
      "Processing Cast skq202214s_022avg.cnv\n",
      "Processing Cast skq202214s_023avg.cnv\n",
      "Processing Cast skq202214s_024avg.cnv\n",
      "Processing Cast skq202214s_025avg.cnv\n",
      "Processing Cast skq202214s_026avg.cnv\n",
      "Processing Cast skq202214s_027avg.cnv\n",
      "Processing Cast skq202214s_028avg.cnv\n",
      "Processing Cast skq202214s_029avg.cnv\n",
      "Processing Cast skq202214s_030avg.cnv\n",
      "Processing Cast skq202214s_031avg.cnv\n",
      "Processing Cast skq202214s_032avg.cnv\n",
      "Processing Cast skq202214s_033avg.cnv\n",
      "Processing Cast skq202214s_035avg.cnv\n",
      "Processing Cast skq202214s_036avg.cnv\n",
      "Processing Cast skq202214s_037avg.cnv\n",
      "Processing Cast skq202214s_038avg.cnv\n",
      "Processing Cast skq202214s_039avg.cnv\n",
      "Processing Cast skq202214s_040avg.cnv\n",
      "Processing Cast skq202214s_041avg.cnv\n",
      "Processing Cast skq202214s_042avg.cnv\n",
      "Processing Cast skq202214s_043avg.cnv\n",
      "Processing Cast skq202214s_044avg.cnv\n",
      "Processing Cast skq202214s_045avg.cnv\n",
      "Processing Cast skq202214s_046avg.cnv\n",
      "Processing Cast skq202214s_047avg.cnv\n",
      "Processing Cast skq202214s_048avg.cnv\n",
      "Processing Cast skq202214s_049avg.cnv\n",
      "Processing Cast skq202214s_050avg.cnv\n",
      "Processing Cast skq202214s_051avg.cnv\n"
     ]
    }
   ],
   "source": [
    "#save downcast csv to file for viewing - really this is just a cleaned up cnv file\n",
    "import pandas as pd\n",
    "for cast in cruise_data.keys():\n",
    "    print(f'Processing Cast {cast}')\n",
    "    cruise_data[cast]['time'] = pd.to_datetime(cruise_data[cast]['time'])\n",
    "    cruise_data[cast].to_csv(sample_data_dir+cast.replace('cnv','csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "581fb1b9-f53d-4a7c-9556-79bebf6d9c92",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/bell/ecoraid/2022/CTDcasts/skq202214s/skq202214s_051avg.csv'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data_dir+cast.replace('cnv','csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37a7008-b911-47bd-ad1a-24fa1d231a51",
   "metadata": {},
   "source": [
    "## Post Cruise Processing with additional meta information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "third-yellow",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################\n",
    "# edit to point to {cruise sepcific} raw datafiles \n",
    "datafile = sample_data_dir+'rawconverted/' #<- point to cruise and process all files within\n",
    "cruise_name = 'SKQ202312' #no hyphens\n",
    "cruise_meta_file = sample_data_dir+'logs/SKQ202312.yaml'\n",
    "inst_meta_file = sample_data_dir+'logs/FOCI_standard_CTD.yaml'\n",
    "group_meta_file = ecofocipy_dir+'staticdata/institutional_meta_example_ctd.yaml'\n",
    "inst_shortname = '' #keep as placeholder for now\n",
    "###############################################################\n",
    "\n",
    "#init and load data\n",
    "cruise = sbe_ctd_parser.sbe9_11p()\n",
    "filename_list = sorted(glob.glob(datafile + '*.cnv'))\n",
    "\n",
    "(cruise_data,cruise_header) = cruise.parse(filename_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ready-audit",
   "metadata": {},
   "source": [
    "## Time Properties\n",
    "\n",
    "Not traditionally dealt with for CTD files as they are likely dynamically updated via GPS feed.  However, FOCI tends to label the date/time with the ***at depth*** time-stamp\n",
    "\n",
    "## Depth Properties and other assumptions\n",
    "\n",
    "- currently, all processing and binning (1m for FOCI) is done via seabird routines and the windows software.  This may change with the python ctd package for a few tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acknowledged-active",
   "metadata": {},
   "source": [
    "## Load all external meta information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "freelance-fairy",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cruise info\n",
    "with open(cruise_meta_file) as file:\n",
    "    cruise_config = yaml.full_load(file)\n",
    "\n",
    "#instrument info\n",
    "with open(inst_meta_file) as file:\n",
    "    inst_config = yaml.full_load(file)\n",
    "\n",
    "#institutional info\n",
    "with open(group_meta_file) as file:\n",
    "    group_config = yaml.full_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c3fd4d-4309-4337-8cc1-8812996a8875",
   "metadata": {},
   "outputs": [],
   "source": [
    "inst_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5aedec2-dc99-4446-9f28-9127ec805049",
   "metadata": {},
   "outputs": [],
   "source": [
    "cruise_config['CTDCasts']['CTD001']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65042aa2-9803-4864-887d-127a690c6193",
   "metadata": {},
   "outputs": [],
   "source": [
    "cruise_data['ctd001.cnv'].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31643660",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for cast in cruise_data.keys():\n",
    "    print(f'Processing Cast {cast}')\n",
    "    try:\n",
    "        #output cruise cast stats here\n",
    "        #cruise_data[cast].describe()\n",
    "        #cruise_data['ctd001.cnv'].hist() - seaborn may have a better summary plot than just a bunch of histograms\n",
    "        #sns.pairplot(cruise_data[cast])\n",
    "\n",
    "        cruise_data[cast] = cruise_data[cast].rename(columns={\n",
    "                            't090C':'temperature_ch1',\n",
    "                            't190C':'temperature_ch2',\n",
    "                            'sal00':'salinity_ch1',\n",
    "                            'sal11':'salinity_ch2',\n",
    "                            'sbox0Mm/Kg':'oxy_conc_ch1',\n",
    "                            'sbeox0ML/L':'oxy_concM_ch1',\n",
    "                            'sbeox0PS':'oxy_percentsat_ch1',\n",
    "                            'sbox1Mm/Kg':'oxy_conc_ch2',\n",
    "                            'sbeox1ML/L':'oxy_concM_ch2',\n",
    "                            'sbeox1PS':'oxy_percentsat_ch2',\n",
    "                            'sigma-t00':'sigma_t_ch1',\n",
    "                            'sigma-t11':'sigma_t_ch2',\n",
    "                            'flECO-AFL':'chlor_fluorescence',\n",
    "                            'turbWETntu0':'turbidity',\n",
    "                            'cstarat0':'Attenuation',\n",
    "                            'cstartr0':'Transmittance',\n",
    "                            'par':'par',\n",
    "                            'empty':'empty', #this will be ignored\n",
    "                            'flag':'flag'})\n",
    "\n",
    "        cruise_data[cast].index.rename('depth',inplace=True)\n",
    "        #cruise_data[cast].sample()\n",
    "\n",
    "        cruise_data_nc = ncCFsave.EcoFOCI_CFnc(df=cruise_data[cast], \n",
    "                                    instrument_yaml=inst_config, \n",
    "                                    operation_yaml=cruise_config,\n",
    "                                    operation_type='ctd')\n",
    "        cruise_data_nc.expand_dimensions(dim_names=['latitude','longitude','time'],geophys_sort=False)\n",
    "        cruise_data_nc.variable_meta_data(variable_keys=list(cruise_data[cast].columns.values),drop_missing=True)\n",
    "        cruise_data_nc.dimension_meta_data(variable_keys=['depth','latitude','longitude'])\n",
    "        cruise_data_nc.temporal_geospatioal_meta_data_ctd(positiveE=False,conscastno=cast.split('.')[0])\n",
    "\n",
    "        cruise_data_nc.var_qcflag_init(dim_names=['depth','latitude','longitude','time'])\n",
    "\n",
    "        #interp to sfc for list of vars\n",
    "        try:\n",
    "            cruise_data_nc.interp2sfc(novars=['par'])\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        #add global attributes\n",
    "        cruise_data_nc.deployment_meta_add(conscastno=cast.upper().split('.')[0])\n",
    "        cruise_data_nc.get_xdf()\n",
    "\n",
    "        #add instituitonal global attributes\n",
    "        cruise_data_nc.institution_meta_add(group_config)\n",
    "\n",
    "        #add creation date/time - provenance data\n",
    "        cruise_data_nc.provinance_meta_add()\n",
    "\n",
    "        #provide intial qc status field\n",
    "        cruise_data_nc.qc_status(qc_status='unknown')\n",
    "\n",
    "        cast_label = cast.split('.')[0].split('d')[-1]\n",
    "        cruise_data_nc.xarray2netcdf_save(xdf = cruise_data_nc.get_xdf(),\n",
    "                                filename=sample_data_dir+cruise_name+'c'+cast_label.zfill(3)+'_ctd.nc',format=\"NETCDF3_CLASSIC\")\n",
    "        #generate editable csv files\n",
    "        to_edit = True\n",
    "        if to_edit:\n",
    "            if not cast[0] in ['d','u']: #dont save editable up and downcast files, just nc files for plotting... all u/d files can be removed after final data\n",
    "                cruise_data_nc.get_xdf().to_dataframe().to_csv(sample_data_dir+cruise_name+'c'+cast_label.zfill(3)+'_ctd.to_edit.csv')  \n",
    "        \n",
    "    except:\n",
    "       print('Conversion Failed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e76212-3a03-443a-b304-6618fa9420e7",
   "metadata": {},
   "source": [
    "## QC Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "insured-vulnerability",
   "metadata": {},
   "outputs": [],
   "source": [
    "import EcoFOCIpy.plots.sbe_ctd_plots as sbe_ctd_plots\n",
    "import os\n",
    "import xarray as xa\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6090ac-ea00-40f4-b668-c72832287995",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data_dir = '/Users/bell/ecoraid/2023/CTDcasts/aq2301/working/' #root path to cruise directory working repo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f45f1a-2c70-4708-a449-0351e3d4086c",
   "metadata": {},
   "source": [
    "### QC of data (plot parameters with other instruments)\n",
    "- be sure to updated the qc_status for the file and the history for future steps\n",
    "- from NRT csv files... make edits then use that to modify netcdf?\n",
    "- **Better Yet** export netcdf files with variable flags to csv and edit then reingest and modify\n",
    "    - modify netcdf in place and provide a qcflag?\n",
    "\n",
    "\n",
    "### Likely first edits\n",
    "- research issues noted in cruise logs\n",
    "- remove failed instrument (clogs, or other challenges that arent correctable)\n",
    "- extrapolate to sfc (not par though)\n",
    "- despike depths (interpolate between depths)\n",
    "- check for common issues\n",
    "    - lags in salinity when going through interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11505a2-6f36-454b-8f46-d5c54c479526",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test for salinity bottle run needs\n",
    "for cast in sorted(os.listdir(sample_data_dir)):\n",
    "    if cast.endswith('.nc'):\n",
    "        try:\n",
    "            cruise_data_nc = xa.load_dataset(sample_data_dir+cast)\n",
    "            saldiff = cruise_data_nc.salinity_ch1 - cruise_data_nc.salinity_ch2\n",
    "            print(f\"{cast}: Profile Averaged Salinity Difference,STD (chan1-chan2){saldiff.mean().values},{saldiff.std().values}\")        \n",
    "            saldiff.plot.hist(bins=50,xlim=[-.05,.05])\n",
    "        except:\n",
    "            print(f\"{cast}: less than two salinity channels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3266f71-f329-4905-b500-562534dad766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following routines will eventually get ported to ecofocipy as subroutines to be called\n",
    "\n",
    "import seawater as sw\n",
    "\n",
    "def sigmat_update(salinity=None,temperature=None):\n",
    "    '''\n",
    "    Changes to T or S (commonly to despike values or apply a salinity offset) will need corresponding changes in sigmat\n",
    "    '''\n",
    "    # calculate sigmaT at 0db gauge pressure (s, t, p=0)\n",
    "    sigt = (sw.eos80.dens0(s=salinity, t=temperature) - 1000)\n",
    "    \n",
    "    return sigt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76870c14-e33d-4bb3-a2ff-906dcc99b27a",
   "metadata": {},
   "source": [
    "## Generate Plots\n",
    "\n",
    "\n",
    "### Make General Plots\n",
    "- 1:1 plots for paired instruments for each cast (tells if a sensor failed)\n",
    "- TS_Sigmat, Chlor/Par/Turb, Oxy,Temp\n",
    "- T/S property property plot\n",
    "- upcast/downcast plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0977254-1e0d-4b7d-ae1a-5b4a6ad79ec0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "calc_sigmat = True\n",
    "\n",
    "for cast in sorted(os.listdir(sample_data_dir)):\n",
    "    if cast.endswith('.nc'):\n",
    "        cruise_data_nc = xa.load_dataset(sample_data_dir+cast)\n",
    "        ctd_df = cruise_data_nc.to_dataframe()\n",
    "        \n",
    "        if calc_sigmat:\n",
    "            #update sigmat (or calculate it I suppose)\n",
    "            sigup = sigmat_update(salinity=ctd_df.salinity_ch1,\n",
    "                                  temperature=ctd_df.temperature_ch1)\n",
    "            ctd_df['sigma_t_ch1'] = sigup\n",
    "            \n",
    "            sigup2 = sigmat_update(salinity=ctd_df.salinity_ch2,\n",
    "                                  temperature=ctd_df.temperature_ch2)\n",
    "            ctd_df['sigma_t_ch2'] = sigup2   \n",
    "        sbe_p = sbe_ctd_plots.CTDProfilePlot()\n",
    "        plt,fig =sbe_p.plot3var(varname=['temperature_ch1','temperature_ch2','salinity_ch1','salinity_ch2','sigma_t_ch1','sigma_t_ch2'],\n",
    "                          xdata=[ctd_df.temperature_ch1,ctd_df.temperature_ch2,ctd_df.salinity_ch1,ctd_df.salinity_ch2,ctd_df.sigma_t_ch1,ctd_df.sigma_t_ch2],\n",
    "                          ydata=ctd_df.index.get_level_values('depth'),\n",
    "                          secondary=True,\n",
    "                          xlabel=['Temperature','Salinity','Sigma-T'])\n",
    "\n",
    "        DefaultSize = fig.get_size_inches()\n",
    "        fig.set_size_inches( (DefaultSize[0], DefaultSize[1]*3) )\n",
    "        plt.savefig(sample_data_dir+cast.replace('.nc','_TempSalSigmat.png'))\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f4a442-947e-47c7-bc46-517c42eec83a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for cast in sorted(os.listdir(sample_data_dir)):\n",
    "    if cast.endswith('.nc'):\n",
    "        cruise_data_nc = xa.load_dataset(sample_data_dir+cast)\n",
    "        ctd_df = cruise_data_nc.to_dataframe()\n",
    "        \n",
    "        sbe_p = sbe_ctd_plots.CTDProfilePlot()\n",
    "        plt,fig =sbe_p.plot2var(varname=['temperature_ch1','temperature_ch2','oxy_percentsat_ch1','oxy_percentsat_ch2'],\n",
    "                          xdata=[ctd_df.temperature_ch1,ctd_df.temperature_ch2,ctd_df.oxy_percentsat_ch1,ctd_df.oxy_percentsat_ch2],\n",
    "                          ydata=ctd_df.index.get_level_values('depth'),\n",
    "                          secondary=True,\n",
    "                          xlabel=['Temperature','Oxygen Saturation'])\n",
    "\n",
    "        DefaultSize = fig.get_size_inches()\n",
    "        fig.set_size_inches( (DefaultSize[0], DefaultSize[1]*3) )\n",
    "        plt.savefig(sample_data_dir+cast.replace('.nc','_TempOxy.png'))\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f894628-4506-44da-9f6c-fefab9471ec7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for cast in sorted(os.listdir(sample_data_dir)):\n",
    "    if cast.endswith('.nc'):\n",
    "        cruise_data_nc = xa.load_dataset(sample_data_dir+cast)\n",
    "        ctd_df = cruise_data_nc.to_dataframe()\n",
    "        \n",
    "        sbe_p = sbe_ctd_plots.CTDProfilePlot()\n",
    "        plt,fig =sbe_p.plot3var(varname=['turbidity','','chlor_fluorescence','','par'],\n",
    "                          xdata=[ctd_df.turbidity,np.array([]),ctd_df.chlor_fluorescence,np.array([]),ctd_df.par,np.array([])],\n",
    "                          ydata=ctd_df.index.get_level_values('depth'),\n",
    "                          secondary=False,\n",
    "                          xlabel=['Turbidity','Fluor','Par'])\n",
    "\n",
    "        DefaultSize = fig.get_size_inches()\n",
    "        fig.set_size_inches( (DefaultSize[0], DefaultSize[1]*3) )\n",
    "        plt.savefig(sample_data_dir+cast.replace('.nc','_TurbFluorPAR.png'))\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77d9507-7b36-4679-beef-d321d07e1494",
   "metadata": {},
   "source": [
    "# Cross Sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4978d35d-43fd-4749-9822-429b28e78f83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd46a6f-1f15-4da4-be24-0894588973c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cruise_data_nc.get_xdf().to_dataframe().columns\n",
    "sns.pairplot(cruise_data_nc.to_dataframe()[['salinity_ch1', 'salinity_ch2',]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3692b3aa-4be1-4a41-a1a2-aef1e5c61ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Export data from nc files\n",
    "# for cast in sorted(os.listdir(sample_data_dir+'working/')):\n",
    "#     if cast.endswith('.nc'):\n",
    "#         cruise_data_nc = xa.load_dataset(sample_data_dir+'working/'+cast)\n",
    "#         cruise_data_nc.to_dataframe().to_csv(sample_data_dir+'working/'+cast.replace('.nc','.to_edit.csv') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a78ab6-d307-470e-be7b-99645db729ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bc96f01bfc9d2c897ec898f99e5079e1d7ab4b93a6c269a5e00afdb6d52f3b37"
  },
  "kernelspec": {
   "display_name": "Python [conda env:py310] *",
   "language": "python",
   "name": "conda-env-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
